# -*- coding: utf-8 -*-
"""18_Practica_Obligatoria_CNN_Transfer_Learning_Fine_Tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NUADacomPf_wkH6zIm6VfCM2ffMSpS1y

![image.png](attachment:image.png)

## PRACTICA OBLIGATORIA: **Transfer Learning y Fine Tuning con CNN**

* La práctica obligatoria de esta unidad consiste en un repetir el ejercicio de construcción de un modelo de clasificación de paisajes pero usando un modelo preentrenado. Descarga este notebook en tu ordenador y trabaja en local. Ten en cuenta que tendrás que descar los directorios de imágenes y datos adicionales, si los hubiera.
* Recuerda que debes subirla a tu repositorio personal antes de la sesión en vivo para que puntúe adecuadamente.  
* Recuerda también que no es necesario que esté perfecta, sólo es necesario que se vea el esfuerzo.
* Esta práctica se resolverá en la sesión en vivo correspondiente y la solución se publicará en el repo del curso.

### Ejercicio 0

Importa los paquetes y módulos que necesites a lo largo del notebook.
"""

# Commented out IPython magic to ensure Python compatibility.
# === Librerías generales ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import random
import cv2
import gc
from time import time
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
from sklearn.utils import shuffle

# === Visualización y configuración ===
# %matplotlib inline
plt.rcParams["figure.figsize"] = (8, 6)

# === Lectura de imágenes ===
from skimage.io import imread

# === Tensorflow y Keras ===
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# === Modelos preentrenados ===
from tensorflow.keras.applications import VGG19, MobileNetV2, InceptionV3, ResNet50
from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess

# Verificación de GPU
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print(tf.test.gpu_device_name())

import kagglehub

# Descarga del dataset "Intel Image Classification"
path = kagglehub.dataset_download("puneet6060/intel-image-classification")

print("Path to dataset files:", path)

"""### Objetivo del ejercicio

Comparar una red convolucional hecha ad-hoc frente a los modelos preentrenados y ajustados con fine tuning y transfer learning. Para ello emplea el dataset de paisajes del conjunto de ejercicios de la unidad anterior.


### Se pide

1. Preparar los datos del modelo y las funciones de visualización, copia para ello todo lo que necesites de las soluciones del ejercicio de clasificación de paisajes de la unidad anterior.

2. Escoger entre uno de los modelos VGG-19, InceptionV3 y MobileNetV2 (todos en https://keras.io/api/applications/) (Se aconseja este último si no tenemos un ordenador muy potente). Si no te haces con estos puedes recurrir a la ResNetV50.

4. Hacer un transfer-learning con una cabeza de como mucho 2 capas densas ocultas y una de salida. Mostrar la evaluación contra test, el report de clasificación y la matriz de confusión.

5. Hacer un fine-tuning con la misma cabeza diseñada en el punto anterior. Mostrar la evaluación contra test, el report de clasificación y la matriz de confusión.

6. Comparar los resultados con los obtenidos con la red convolucional del ejercicio mencionado.

EXTRA:
- Repetir el transfer learning empleando aumentado de imágenes.


"""

# path descargado con kagglehub
ROOT_PATH = path

# Rutas a los datos de entrenamiento y test
TRAIN_PATH = ROOT_PATH + "/seg_train/seg_train/"
TEST_PATH  = ROOT_PATH + "/seg_test/seg_test/"

# Comprobamos qué clases hay en cada conjunto
print("Clases en entrenamiento:", os.listdir(TRAIN_PATH))
print("Clases en test:", os.listdir(TEST_PATH))

# Leer una imagen de la clase "sea"
img = imread(TRAIN_PATH + "/sea/11321.jpg")

# Mostrar
plt.imshow(img)
plt.axis('off')
plt.title("Ejemplo de imagen – clase 'sea'")
plt.show()

print("Forma de la imagen:", img.shape)

# Parámetros globales de tamaño de imagen
IMG_WIDTH = IMG_HEIGHT = 75

def read_data(directorio, reshape_dim=(IMG_WIDTH, IMG_HEIGHT)):
    X = []
    y = []

    for folder in os.listdir(directorio):
        print(folder)
        folder_path = os.path.join(directorio, folder)
        if os.path.isdir(folder_path):
            for file in os.listdir(folder_path):
                image = imread(os.path.join(directorio, folder, file))
                image = cv2.resize(image, reshape_dim)
                X.append(image)
                y.append(folder)

    return np.array(X), np.array(y)

def show_images_batch(paisajes, names=[], n_cols=5, size_scale=2):
    n_rows = (len(paisajes) - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * size_scale, n_rows * 1.1 * size_scale))

    for index, paisaje in enumerate(paisajes):
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(paisaje, cmap="Greys")
        plt.axis("off")
        if len(names):
            plt.title(names[index])

    plt.tight_layout()
    plt.show()

X_train, y_train = read_data(TRAIN_PATH)
X_test, y_test = read_data(TEST_PATH)

# Seleccionar 20 índices aleatorios del conjunto de entrenamiento
indices = np.random.randint(0, len(X_train), 20)

# Mostrar las imágenes seleccionadas y sus etiquetas
show_images_batch(X_train[indices], names=y_train[indices], n_cols=5)

# Ver dimensiones de los conjuntos de datos
print("X_train shape:", X_train.shape)
print("X_train size:", X_train.size)
print("X_test shape:", X_test.shape)

# Escalado: normalizamos los valores de píxeles al rango [0, 1]
X_train = X_train / 255.0
X_test = X_test / 255.0

from keras.applications import InceptionV3

# Cargamos InceptionV3 sin la capa final (include_top=False)
test_model = InceptionV3(
    include_top=False,
    weights='imagenet',
    input_shape=(75, 75, 3)
)

# Ver forma esperada de entrada y salida
print("Input shape:", test_model.input)
print("Output shape:", test_model.output)

# Eliminamos el modelo de prueba para liberar memoria
del test_model
gc.collect()

# Construcción del modelo para Transfer Learning
IMG_WIDTH = IMG_HEIGHT = 75  # asegúrate de que estas variables estén definidas antes

# Cargamos la base del modelo preentrenado
base_model = InceptionV3(
    include_top=False,
    weights='imagenet',
    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)
)

# Congelamos las capas convolucionales del modelo base
for layer in base_model.layers:
    layer.trainable = False

def prepare_model(base_model=base_model):
    """
    Añade una cabeza densa a un modelo preentrenado congelado y lo compila.
    """
    # Aplanado de la salida de InceptionV3
    x = keras.layers.Flatten()(base_model.output)

    # Capa oculta densa
    x = keras.layers.Dense(2048, activation='relu')(x)
    x = keras.layers.Dropout(rate=0.25)(x)

    # Capa de salida para 6 clases (con softmax)
    x = keras.layers.Dense(6, activation='softmax')(x)

    # Modelo completo
    model = keras.Model(base_model.input, x)

    # Compilación
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',  # usamos sparse porque las etiquetas son enteros
        metrics=['acc']
    )

    return model

model = prepare_model()
model.summary()

instancias_train = len(X_train)  # Número total de imágenes de entrenamiento

# Comprobamos cómo varía el número de pasos por época según el batch size
for i in range(1, 5):
    batch_size = 32 * i
    steps = round(instancias_train * 0.8 / batch_size)
    print(f"Batch_size: {batch_size}, num_steps_per_epoch: {steps}")

# Convertimos las etiquetas a una Serie de pandas para trabajar con ellas
targets = pd.Series(y_train)

# Creamos un diccionario de clase → número
mapa = {tipo: indice for indice, tipo in enumerate(targets.unique())}
print(mapa)

# Reemplazamos las etiquetas por sus equivalentes numéricos
y_train = np.array([mapa[clase] for clase in y_train])
y_test  = np.array([mapa[clase] for clase in y_test])

# Si ya tenemos etiquetas codificadas como enteros, simplemente las asignamos
y_train_num = y_train
y_test_num = y_test

# Barajamos los datos
from sklearn.utils import shuffle
X_train_s, y_train_s = shuffle(X_train, y_train_num)

from time import time

# Evaluamos distintos batch_size para estimar tiempos de entrenamiento
for batch_size in [32, 64, 96, 128]:
    t_zero = time()

    model = prepare_model()
    model.fit(
        X_train,
        y_train_num,
        batch_size=batch_size,
        validation_split=0.2,
        epochs=1,
        verbose=0
    )

    tiempo = round(time() - t_zero, 3)

    # Liberamos memoria tras cada prueba
    del model
    gc.collect()

    print(f"batch_size: {batch_size}, num_steps: {len(X_train) // batch_size}, tiempo 1 epoca: {tiempo}, tiempo 20 épocas: {tiempo * 20}")

batch_size = 128

# Definimos early stopping
earlyS = keras.callbacks.EarlyStopping(
    patience=10,
    restore_best_weights=True
)

# Entrenamiento completo con control de tiempo
t_zero = time()

model = prepare_model()
history = model.fit(
    X_train_s,
    y_train_s,
    batch_size=batch_size,
    validation_split=0.2,
    epochs=40,
    callbacks=[earlyS],
    verbose=1
)

tiempo = round(time() - t_zero, 3)
print(f"Tiempo total de entrenamiento: {tiempo} segundos")